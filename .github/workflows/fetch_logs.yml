name: VIVES anomaly detection - ETL

on:
  schedule:
    - cron: "*/5 * * * *"  # Every 5 minutes
  workflow_dispatch:

jobs:
  etl-detect-pipeline:
    runs-on: ubuntu-latest

    env:
      ES_HOST: ${{ secrets.ES_HOST }}
      ES_API_KEY: ${{ secrets.ES_API_KEY }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Fetch last 5 minutes of logs from Elasticsearch
        run: python src/elasticsearch_import.py

      - name: Debug model files
        run: |
          echo "Current working directory: $(pwd)"
          echo "Listing models directory:"
          ls -lh models || echo "⚠️ models folder missing"
          file models/ip_encoder_hashing.pkl || echo "⚠️ encoder file unreadable"
          python -c "import joblib; print('✅ Joblib import ok'); joblib.load('models/ip_encoder_hashing.pkl')" || echo '❌ Failed to load encoder'      

      - name: Run anomaly detection models on fresh logs
        run: python src/ML_batch_scan.py

      - name: Export logs and predictions to Elasticsearch
        run: python src/elasticsearch_export.py
